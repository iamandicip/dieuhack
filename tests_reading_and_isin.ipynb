{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Isin are consider unique, if several documents have the same isin, merge the results.\n",
    "Only consider one value for each field only cities can have multiple values. (and 1 isin can have multiple files)\n",
    "Need to math the name in the files, may not be an exact match with the db or reality because the exact name is not always\n",
    "well diffined (in the db at least...)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# path\n",
    "data0='data_0'\n",
    "data1='data_1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import the labels an place them in a dict with key == isin\n",
    "import csv\n",
    "import os\n",
    "import copy\n",
    "import collections\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "class label(dict):\n",
    "    \n",
    "    def __init__(self):\n",
    "        '''\n",
    "        create an empty dict for holding the label info.\n",
    "        '''\n",
    "        self.header=[]\n",
    "        \n",
    "    @classmethod\n",
    "    def from_cvs(cls,datafolder):\n",
    "        '''\n",
    "        Create a new dictionary with the all the label loaded for the labels and cities cvs\n",
    "        file from the folder datafolder.\n",
    "        \n",
    "        args:\n",
    "            datafolder: the folder where the labels.csv and cities.csv files are.\n",
    "        '''\n",
    "        assert os.path.isdir(datafolder)\n",
    "        self=cls()\n",
    "        l=0\n",
    "        with open(os.path.join(data0,'labels.csv'),'r') as csvfile:\n",
    "                reader=csv.reader(csvfile)\n",
    "                header=reader.next()    \n",
    "                l=len(header)\n",
    "                for data in reader:\n",
    "                    fileid_t=data[0]\n",
    "                    isin_t=data[1]\n",
    "                    # safty check:\n",
    "                    if isin_t not in self:\n",
    "                        if len(data) != l:\n",
    "                            print 'icoherent data lengths'\n",
    "                        self[isin_t]=data[2:]\n",
    "                        self[isin_t].insert(0,[fileid_t])\n",
    "                    else:\n",
    "                        self[isin_t][0].append(fileid_t)\n",
    "                        if self[isin_t][1:] != data[2:]:\n",
    "                            print self[isin_t][1:] \n",
    "                            print data[2:]\n",
    "                            raise ValueError('inconsistancy !')         \n",
    "        l-=1\n",
    "        with open(os.path.join(data0,'cities.csv'),'r') as csvfile:\n",
    "                reader=csv.reader(csvfile)\n",
    "                header2=reader.next()\n",
    "                header=header[2:]\n",
    "                header.extend(header2[2:])\n",
    "                self.header=header\n",
    "                self.header.insert(0,header2[0])\n",
    "                print self.header\n",
    "                for data in reader:      \n",
    "                    fileid_t=data[0]\n",
    "                    isin_t=data[1]\n",
    "                    data=data[2:]\n",
    "\n",
    "                    # safty check:\n",
    "                    if fileid_t not in self[isin_t][0]:\n",
    "                        raise ValueError('file id do not match between cities and lables !')\n",
    "\n",
    "                    if len(self[isin_t]) == l: # still no cites \n",
    "                        self[isin_t].extend([[data[0]],[data[1]]])\n",
    "                    else: \n",
    "                        self[isin_t][-2].append(data[0])\n",
    "                        self[isin_t][-1].append(data[1])\n",
    "                        \n",
    "        for item in self:\n",
    "            if len(self[item]) < len(self.header):\n",
    "                self[item].extend([None,None])\n",
    "                        \n",
    "        return self\n",
    "        \n",
    "    @classmethod\n",
    "    def from_folder(cls, datafolder, header):\n",
    "        '''\n",
    "        Initialize the dictionary with all the files in the given folder. The files are not read,\n",
    "        this method only import all the files names and extract the isin from the name of\n",
    "        the file is possible for each of them, and the array\n",
    "        of data is initialized for each of the isin, all the data are initialized to None (appart for the \n",
    "        filepath... ).\n",
    "        \n",
    "        if the isin is unknow, the files are append to the list self.unknown \n",
    "        \n",
    "        The files are expected to be formated as (fileid)_i(isin)_(stuff...)\n",
    "        \n",
    "        args:\n",
    "            datafolder: folder where the data are.\n",
    "            header: header for the data, this is the label for each of the element stored for each isin.\n",
    "                    the first data is always the 'fileId', so you should always have the label as a fist \n",
    "                    element of your header.\n",
    "                    e.g: header= ['fileId', 'NOMINAL.CURR', 'MIN.TRAD.AMT', 'MULT.TRAD.AMT', 'ZERO.COUPN.FLAG', \n",
    "                    'SEC.SUB.ID', 'FUNG.FL', 'OpCurrency', 'issuerName', 'issuerCity', 'issuerCountry', \n",
    "                    'guarantorName', 'guarantorCity', 'guarantorCountry', 'City.Id', 'City.Name']\n",
    "                    \n",
    "        '''\n",
    "        assert os.path.isdir(datafolder)\n",
    "        self=cls()\n",
    "        self.header=header\n",
    "        self.unknown=[]\n",
    "        for filename in os.listdir(datafolder):\n",
    "            isin=re.findall('[a-zA-Z][a-zA-Z][0-9][0-9][0-9][0-9][0-9][0-9][0-9][0-9][0-9][0-9]',filename)\n",
    "            if len(isin) > 1 :\n",
    "                raise ValueError('multpiple isin !')\n",
    "            elif len(isin) == 1:\n",
    "                if isin[0] in self:\n",
    "                    self[isin[0]][0].append(filename)\n",
    "                else:\n",
    "                    self[isin[0]]=[[filename]]\n",
    "                    self[isin[0]].extend([None]*(len(self.header)-1))\n",
    "            #isin=filename.split('_')[1]\n",
    "            #if 'I' == isin[0].upper():\n",
    "            #    if isin[1:] in self:\n",
    "            #        self[isin[1:]][0].append(filename)\n",
    "            #    else:\n",
    "            #        self[isin[1:]]=[[filename]]\n",
    "            #        self[isin[1:]].extend([None]*(len(self.header)-1))\n",
    "            #elif re.match('[a-zA-Z][a-zA-Z][0-9][0-9][0-9][0-9][0-9][0-9][0-9][0-9][0-9][0-9]', isin):              \n",
    "            #    if isin in self:\n",
    "            #        self[isin][0].append(filename)\n",
    "            #    else:\n",
    "            #        self[isin]=[[filename]]\n",
    "            #        self[isin].extend([None]*(len(self.header)-1))\n",
    "            else:\n",
    "                self.unknown.append(filename)\n",
    "        return self\n",
    "        \n",
    "    def get_headers(self):\n",
    "        '''\n",
    "        Retrun the header as a list, this is all the possible filed store for each isin.\n",
    "        '''\n",
    "        return copy.deepcopy(self.header)\n",
    "        \n",
    "    def get_isin(self, isin, label=None):\n",
    "        '''\n",
    "        Provide the data for a given isin and label, all the possible label are given by get_headers().\n",
    "            \n",
    "        args:\n",
    "            isin: the isin...\n",
    "            lable: data data you want for this isin, is None, all the data for this isin are returned\n",
    "        '''\n",
    "        if label is not None:\n",
    "            assert label in self.header\n",
    "            return copy.deepcopy(self[isin][label])\n",
    "        else:\n",
    "            return copy.deepcopy(self[isin])\n",
    "        \n",
    "    def get_from_field(self,field, value):\n",
    "        '''\n",
    "        Return a list of isin that have the given value for the give field.\n",
    "        \n",
    "        The research is done by going through the compleate list, this is therfore ineficient.\n",
    "        \n",
    "        args:\n",
    "            field: one of the label in the header where to look for the value\n",
    "            value: value to look for.\n",
    "        '''\n",
    "        result=[]\n",
    "        for item in self:\n",
    "            tmp = self[item][self.header.index(field)]\n",
    "            if tmp is not None and (tmp == value or value in tmp) :\n",
    "                result.append(item)\n",
    "        return result\n",
    "    \n",
    "    def empty(self):\n",
    "        '''\n",
    "        Empty the all the data (set them to None), only keep the isin and the fileId associeted.\n",
    "        '''\n",
    "        l=len(self.header)\n",
    "        for item in self:\n",
    "            for x in xrange(1,l):\n",
    "                self[item][x]=None\n",
    "            \n",
    "    def evaluate(self, what, ref, printerr=True):\n",
    "        '''\n",
    "        Compare the values from this set to a reference set.\n",
    "        \n",
    "        Args:\n",
    "            what: index of the data to compare (see header label)\n",
    "            ref: another label object to compare with.\n",
    "            printerr: print not matching entity\n",
    "        '''\n",
    "        total=0\n",
    "        notcomp=0\n",
    "        err=np.zeros(len(what))\n",
    "        lookup=dict()\n",
    "        for i in xrange(0,len(what)):\n",
    "            lookup[what[i]]=i\n",
    "            \n",
    "        for item in ref:\n",
    "            if item not in self:\n",
    "                print item+' is not in the set !'\n",
    "                notcomp+=1\n",
    "            else:\n",
    "                total+=1\n",
    "                for idx in what:\n",
    "                    if self[item][idx] != ref[item][idx]:\n",
    "                        if printerr:\n",
    "                            print item, self[item][idx], ref[item][idx]\n",
    "                        err[lookup[idx]]+=1\n",
    "        print \n",
    "        print 'total number of set compared: '+str(total)\n",
    "        print 'total number of missing set: '+str(notcomp)\n",
    "        print 'total number of errors for each index: '+str(err)\n",
    "        print 'error %: '+str(err/total*100)\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fileId', 'NOMINAL.CURR', 'MIN.TRAD.AMT', 'MULT.TRAD.AMT', 'ZERO.COUPN.FLAG', 'SEC.SUB.ID', 'FUNG.FL', 'OpCurrency', 'issuerName', 'issuerCity', 'issuerCountry', 'guarantorName', 'guarantorCity', 'guarantorCountry', 'City.Id', 'City.Name']\n"
     ]
    }
   ],
   "source": [
    "labels=label.from_cvs(data0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "File ids are unique, not isin (multiple file for one isin...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "total number of set compared: 1200\n",
      "total number of missing set: 0\n",
      "total number of errors for each index: [ 0.  0.  0.  0.]\n",
      "error %: [ 0.  0.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "labels.evaluate([0,1,2,3],labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "total number of set compared: 1200\n",
      "total number of missing set: 0\n",
      "total number of errors for each index: [ 1200.]\n",
      "error %: [ 100.]\n"
     ]
    }
   ],
   "source": [
    "data=copy.deepcopy(labels)\n",
    "data.empty()\n",
    "data.evaluate([1],labels,printerr=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DE000UZ165E9']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.get_from_field('fileId','0900045c82a4ae5c')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['0900045c82d3b389'],\n",
       " 'USD',\n",
       " '0.00E+00',\n",
       " '1.00E+06',\n",
       " 'N',\n",
       " 'USUB',\n",
       " 'N',\n",
       " 'USD',\n",
       " 'CREDIT SUISSE INTERNATIONAL',\n",
       " 'LONDON',\n",
       " 'UNITED KINGDOM',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " ['HONG', 'NEW Y'],\n",
       " ['HONG KONG', 'NEW YORK']]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.get_isin('XS1183229084')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create a dict with all the files to analize, when the isin can be extracted from the name,\n",
    "# it is directly used for indexing, if not found in the name, the files are added to the unknown list.\n",
    "data=label.from_folder(os.path.join(data0,'txt'), header=['fileId', 'NOMINAL.CURR', 'MIN.TRAD.AMT',\n",
    "                                                       'MULT.TRAD.AMT', 'ZERO.COUPN.FLAG', 'SEC.SUB.ID',\n",
    "                                                       'FUNG.FL', 'OpCurrency', 'issuerName', 'issuerCity', \n",
    "                                                       'issuerCountry', 'guarantorName', 'guarantorCity', \n",
    "                                                       'guarantorCountry', 'City.Id', 'City.Name']\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n"
     ]
    }
   ],
   "source": [
    "print data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use pdf, an try to extract the text, if it fail, converte to image with high dpi and pre process the image with different parameters\n",
    "and use tesarac ocr to get the text.\n",
    "\n",
    "Use the isin to detect is the text seems correct, if isin detectrion fail, reject the de ocr. if all doc are rejected, print a error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n",
      " Pricing Supplement dated 26 March 2015 Credit Suisse International 3-Year 10-Month USD Notes due January 2019 linked to the Credit Suisse SPEAR Dynamic Asia Index Total Return USD  Series X (the \"Securities\") issued pursuant to the Structured Products Programme for the issuance of Notes, Certificates and Warrants PART A  CONTRACTUAL TERMS Terms used herein shall be deemed to be defined as such for the purposes of the Programme Memorandum dated 10 July 2013. This document constitutes the Pricing Supplement of the Securities described herein. Copies of the Programme Memorandum may be obtained from the registered office of the Issuer and the offices of the Agents specified herein.  This Pricing Supplement comprises the final terms for the issuance of the Securities.  This Pricing Supplement does not constitute final terms for the purposes of Article 5.4 of Directive 2003/71/EC as amended by Directive 2010/73/EU Directive (the \"Prospectus Directive\"). The Issuer is not offering the Securities in any jurisdiction in circumstances which would require a prospectus pursuant to the Prospectus Directive. Nor is any person authorised to make such an offer of the Securities on behalf of the Issuer in any jurisdiction. In addition, no application has been made (nor is it proposed that any application will be made) for listing of the Securities on any stock exchange. 1. Issuer: Credit Suisse International 2. Series Number: 11842 3. Tranche Number: Not Applicable 4. Applicable General Terms and Conditions: General Note Conditions 5. Settlement Currency: USD 6. Aggregate Nominal Amount: USD 7,000,000  (i) Series: 1  (ii)  Tranche: Not Applicable 7. Issue Price: 98.9769095714286 per cent. of the Aggregate Nominal Amount  8. Specified Denomination: USD 1,000,000, the denomination of the note at the time of issue shall not be subsequently divided into a lower denomination  9. Minimum Transfer Amount: Not Applicable 10. Minimum Trading Lot: Not Applicable 11. Issue Date: 10 Business Days following the Trade Date, expected to be 26 March 2015 12. Maturity Date: 5 Business Days immediately following the Valuation Date (expected to be 14 January 2019) 13. Interest Basis: Not Applicable 14. Premium Basis: Not Applicable \n"
     ]
    }
   ],
   "source": [
    "import PyPDF2\n",
    "pdfFileObj = open('data_0/pdf/0900045c82ef7d9b_IXS1205574913_F_PC_N_M.pdf', 'rb')\n",
    "pdfReader = PyPDF2.PdfFileReader(pdfFileObj)\n",
    "print pdfReader.numPages\n",
    "pageObj = pdfReader.getPage(0)\n",
    "print pageObj.extractText()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "˘!( (!  ˜!\"$#!-˚\"'˙˚˚/˚3)˙*'3˚'˚˚'*ˆ*40˙*˚520˙4ˆˆ'&/ˇ:˛!˚5(˙ˆ'7ˇ)˝,!˙+5˙'45(2#˙˙+0ˇ=)˙+5˙'45(2.˙*ˇ)+5˙'45(2(4)ˇ)+-˚53>˙=\"&)=)˙+0ˇ)˙˙+0ˇ2\"-ˇ)+0ˇ(4)ˇ)+0ˇ-˙˙ˇ)+0ˇ:'˚)ˇ)+0ˇˇˇ)+0ˇ\n",
      ")ˆˆ˚ˆ)*ˆ˛ˆˆ˙+˛ˆˆ˝ˆˆ˙˚˙ˆ)ˆ˚ˆ˚ˆ˛,-../˘ˆ˙ˆ˙)ˆˆ˚ˆˇ˙)ˆˆ˚ˆ˛˘ˆˆˆˆ˚ˆ)ˆ˚0ˆ˛˚1+ˆ2˚ˆ˘ˆ3˚0ˆ˛ˆˆ1ˆ˛/)ˆˆ˚ˆ˘˛ˆ˛ˆˆ˙˛˛˙+))ˆ˚ˆ˙ˆ˛˛/˛˛)ˆ˛˚˛ˆˆ˛/˚ˆ˛˙ˆˆ˙ˆ˝˚˛˚˙ˆ)ˆˆ˚ˆ4ˆ˝˚˛5ˇˇ3)ˆˆˆ˘)*ˆˆˆˆˆ˙)ˆ˚ˆ˛˚ˆ˛ˆ˛+))ˆ˛ˆ˙ˆ˛)ˆˆ˚ˆ˛˚˙ˆ)ˆ˚ˆ˙ˆ˛˛6˚ˆ˛ˆˆ˛ˆ˝˚˛˙˛˝˛)ˆˆ˚ˆ˛)ˆˆˆ*˛ˆ1)˝ˆ//ˆ˙)ˆˆ3˛˙ˆ˛˛)ˆˆ˙ˆ˚)ˆˆ˛˛˛ˆ˙ˆ˛)ˆˆ˚ˆ˙˙˚˛˛)ˆˆˆ˘/)ˆˆ˛ˆ˚˙)ˆ˚ˆ˘ˆ˛ˆ˚ˆˆˆ4˚)ˆ˙ˆ5)ˆˆ˛ˆ˚3˚ˆ˙ˆˆ˛+)˛)˛˙)˛˝˛+ˆ˚0ˆ˛˘˛˚˙ˆ)ˆ˚ˆ˙ˆ˛˘ˆ1+/˚˙˝)ˆ˘˛˛*˙ˆ˙ˆ˛,789ˇ˙,:;<ˇ˛)ˆˆˆ*ˆ˚ˆ˛˙ˆ˛,-;7/˘ˆ˙ˆ˙3\n"
     ]
    }
   ],
   "source": [
    "pageObj = pdfReader.getPage(2)\n",
    "print pageObj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import PyPDF2\n",
    "import tempfile\n",
    "import PythonMagick\n",
    "import Image\n",
    "from pytesseract import image_to_string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Terms\n",
      "Ill BARCLAYS\n",
      "\n",
      "BARCLAYS BANK PLC\n",
      "\n",
      "(Incorporated with limited liability in England and Wales)\n",
      "\n",
      " \n",
      "\n",
      "BARCLAYS CAPITAL (CAYMAN) LIMITED\n",
      "\n",
      "(Incorporated with limited liability in the Cayman Islands)\n",
      "\n",
      "GLOBAL STRUCTURED SECURITIES PROGRAMME\n",
      "\n",
      "for the issue of Securities\n",
      "\n",
      "BARCLAYS BANK PLC\n",
      "EUR 5,000,000 Inﬂation Linked Notes due 13 April 2021 (the “Notes”)\n",
      "Series GSN40028\n",
      "\n",
      "under the Global Structured Securities Programme\n",
      "\n",
      "Issue Price: 100 per cent. of par\n",
      "\n",
      "This document constitutes the final terms of the Notes (the “Final Terms”) described herein for the purposes of Article 5.4 of the\n",
      "Directive 2003/ 71/ EC and is prepared in connection with the Global Structured Securities Programme established by Barclays Bank\n",
      "PLC (the “Bank”) and Barclays Capital (Cayman) Limited (“BCCL”) and is supplemental to and should be read in conjunction with the\n",
      "Base Prospectus dated 6 August 2010, as supplemented and amended from time to time, which constitutes a base prospectus (the\n",
      "“Base Prospectus”) for the purpose of the Directive 2003/ 71 / EC. Full information on the Issuer and the offer of the Securities is only\n",
      "available on the basis of the combination of these Final Terms and the Base Prospectus. The Base Prospectus is available for viewing\n",
      "during normal business hours at the registered office of the Issuer and the specified office of the Issue and Paying Agent for the time\n",
      "being in London and copies may be obtained from such office. Words and expressions defined in the Base Prospectus and not\n",
      "defined in this document shall bear the same meanings when used herein.\n",
      "\n",
      "The Issuer accepts responsibility for the information contained in these Final Terms. To the best of its knowledge and belief (having\n",
      "taken all reasonable care to ensure that such is the case) the information contained in these Final Terms is in accordance with the\n",
      "facts and does not contain anything likely to affect the import of such information.\n",
      "\n",
      "Investors should refer to the sections headed “Risk Factors” in the Base Prospectus for a discussion of certain matters that should be\n",
      "considered when making a decision to invest in the Securities.\n",
      "\n",
      "Barclays Capital\n",
      "\n",
      "Final Terms dated 13 April 2011\n",
      "The distribution of this document and the offer of the Securities in certain jurisdictions may be\n",
      "restricted by law. Persons into whose possession these Final Terms come are required by the Bank to\n",
      "inform themselves about and to observe any such restrictions. Details of selling restrictions for\n",
      "various jurisdictions are set out in “Purchase and Sale” in the Base Prospectus. In particular, the\n",
      "Securities have not been, and will not be, registered under the US Securities Act of 1933, as amended,\n",
      "and are subject to US tax law requirements. Trading in the Securities has not been approved by the US\n",
      "Commodity Futures Trading Commission under the US Commodity Exchange Act of 1936, as\n",
      "amended. Subject to certain exceptions, the Securities may not at any time be offered, sold or\n",
      "delivered in the United States or to US persons, nor may any US persons at any time trade or maintain\n",
      "a position in such Securities.\n",
      "Part A\n",
      "Terms and Conditions of the Securities\n",
      "\n",
      "The Securities shall have the following terms and conditions, which shall complete, modify and/or\n",
      "amend the Base Conditions and/ or any applicable Relevant Annex(es) set out in the Base Prospectus\n",
      "dated 6 August 2010.\n",
      "\n",
      "Parties\n",
      "\n",
      "lssuer: Barclays Bank PLC\n",
      "Guarantor: N/A\n",
      "\n",
      "Manager: Barclays Bank PLC\n",
      "Determination Agent: Barclays Bank PLC\n",
      "Issue and Paying Agent: The Bank of New York Mellon\n",
      "Stabilising Manager: N/A\n",
      "\n",
      "Registrar: N/ A\n",
      "\n",
      "CREST Agent: N/ A\n",
      "\n",
      "Paying Agents: N/ A\n",
      "\n",
      "Transfer Agent: N/ A\n",
      "\n",
      "Exchange Agent: N/ A\n",
      "\n",
      "Additional Agents: N/ A\n",
      "\n",
      "THE SECURITIES HAVE NOT BEEN AND WILL NOT BE REGISTERED UNDER THE US SECURITIES ACT\n",
      "OF 1933, AS AMENDED (THE SECURITIES ACT) AND THE SECURITIES COMPRISE BEARER\n",
      "SECURITIES THAT ARE SUBJECT TO US TAX LAW REQUIREMENTS. SUBJECT TO CERTAIN\n",
      "EXCEPTIONS, THE SECURITIES MAY NOT BE OFFERED OR SOLD WITHIN THE UNITED STATES OR\n",
      "TO, OR FOR THE ACCOUNT OR BENEFIT OF, US PERSONS (AS DEFINED IN REGULATION S UNDER\n",
      "THE SECURITIES ACT (“REGULATION S”)). THESE FINAL TERMS HAVE BEEN PREPARED BY THE\n",
      "ISSUER FOR USE IN CONNECTION WITH THE OFFER AND SALE OF THE SECURITIES OUTSIDE THE\n",
      "UNITED STATES TO NON-US PERSONS IN RELIANCE ON REGULATION S AND FOR LISTING OF THE\n",
      "SECURITIES ON THE RELEVANT STOCK EXCHANGE, IF ANY, AS STATED HEREIN. FOR A\n",
      "DESCRIPTION OF THESE AND CERTAIN FURTHER RESTRICTIONS ON OFFERS AND SALES OF THE\n",
      "SECURITIES AND DISTRIBUTION OF THESE FINAL TERMS, THE BASE PROSPECTUS AND THE\n",
      "SUPPLEMENTAL PROSPECTUSES SEE “PURCHASE AND SALE” IN THE BASE PROSPECTUS.\n",
      "\n",
      "ANY UNITED STATES PERSON WHO HOLDS THIS OBLIGATION WILL BE SUBJECT TO LIMITATIONS\n",
      "UNDER THE UNITED STATES INCOME TAX LAWS, INCLUDING THE LIMITATIONS PROVIDED IN\n",
      "SECTIONS 165(j) AND 1287(a) OF THE INTERNAL REVENUE CODE OF 1986, AS AMENDED.\n",
      "Provisions relating to the Securities\n",
      "\n",
      "1 (i) Series: GSN40028\n",
      "(ii) Tranche: 1\n",
      "\n",
      "2 Currency: Euro (“EUR”)\n",
      "\n",
      "3 Notes: Applicable\n",
      "\n",
      "(i) Aggregate Nominal Amount as at EUR 5,000,000\n",
      "the Issue Date:\n",
      "\n",
      "(ii) Specified Denomination: EUR 100,000\n",
      "\n",
      "(iii) Calculation Amount per Security as EUR 1,000\n",
      "at the Issue Date:\n",
      "\n",
      "4 Certificates: N/ A\n",
      "5 Form:\n",
      "(i) GIobaI/Definitive/Uncertificated and Global Bearer Securities:\n",
      "dematel’ialisedi Temporary Global Security, exchangeable for\n",
      "\n",
      "a Permanent Global Security\n",
      "\n",
      "(ii) NGN Form: Applicable\n",
      "(iii) Held under the NSS: N/A\n",
      "(iv) CGN Form: N/A\n",
      "(v) CDIs: N/A\n",
      "6 Trade Date: 30 March 2011\n",
      "7 Issue Date: 13 April 2011\n",
      "8 Redemption Date: 13 April 2021, subject to adjustment in\n",
      "accordance with the Business Day\n",
      "Convention\n",
      "9 Issue Price: 100.00 per cent of the Aggregate Nominal\n",
      "Amount\n",
      "10 Relevant Stock Exchange: London Stock Exchange\n",
      "11 The following Relevant Annex shall apply to Inﬂation Linked Annex\n",
      "\n",
      "the Securities:\n",
      "Provisions relating to interest (if any) payable on the Securities\n",
      "12 Interest: Applicable\n",
      "\n",
      "13 Interest Amount: (i) On the Interest Payment Datem, (where\n",
      "“t” represent a number from 1 to 2), the\n",
      "Issuer will pay to the Securityholder, in\n",
      "respect of each Security an amount\n",
      "calculated as follows:\n",
      "\n",
      "Calculation Amount x 4.80 per cent. per\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "\n",
      "18\n",
      "\n",
      "19\n",
      "20\n",
      "21\n",
      "\n",
      "Interest Rate:\n",
      "Screen Rate Determination:\n",
      "\n",
      "ISDA Determination:\n",
      "Margin:\n",
      "\n",
      "Minimum/Maximum Interest Rate:\n",
      "\n",
      "(i) Minimum Interest Rate\n",
      "\n",
      "(ii) Maximum Interest Rate\n",
      "\n",
      "Interest Commencement Date:\n",
      "Interest Determination Date:\n",
      "\n",
      "Interest Calculation Periods:\n",
      "\n",
      "(i) Interest Period End Dates:\n",
      "\n",
      "(ii) Interest calculation method for short\n",
      "or long Interest Calculation Periods:\n",
      "\n",
      "annum\n",
      "\n",
      "(ii) On the Interest Payment Date(t), (where\n",
      "“t” represents a number from 3 to 10), the\n",
      "Issuer will pay to the SecurityhoIder, in\n",
      "respect of each Security an amount\n",
      "calculated as follows:\n",
      "\n",
      "Calculation Amount x max(YoY EURHICPx +\n",
      "Margin, Minimum Interest Rate)\n",
      "\n",
      "where:\n",
      "\n",
      "“EUR CPIgm” means, in respect of each\n",
      "Interest Payment Date, the Index Level in\n",
      "respect of the Reference Month applicable to\n",
      "the relevant Interest Payment Date;\n",
      "\n",
      "“EUR CPI15m” means, in respect of each\n",
      "Interest Payment Date, the Index Level in\n",
      "respect of the Reference Month applicable to\n",
      "the relevant Interest Payment Date;\n",
      "\n",
      "“Index Level” means in respect of any\n",
      "reference Month, the level of the Index for\n",
      "such Reference Month; and\n",
      "\n",
      "“YoY EURHICPX” means EUR CP13m / EUR\n",
      "CPl15m — 1.\n",
      "\n",
      "N/A\n",
      "N/A\n",
      "\n",
      "N/ A\n",
      "2.00 per cent.\n",
      "\n",
      "2.00 per cent. per annum\n",
      "N/ A\n",
      "\n",
      "Issue Date\n",
      "N/ A\n",
      "\n",
      "As defined in Condition 24 of the Base\n",
      "Conditions\n",
      "\n",
      "Each Interest Payment Date without any\n",
      "adjustment in accordance with the Business\n",
      "Day Convention\n",
      "\n",
      "N/A\n"
     ]
    }
   ],
   "source": [
    "filename='data_0/pdf/0900045c80b013e1_ixs0586130022_f_pc_n_m.pdf'\n",
    "pdf_im = PyPDF2.PdfFileReader(file(filename, \"rb\"))\n",
    "npage = pdf_im.getNumPages()\n",
    "pdf_im = None\n",
    "for p in xrange(0,5):\n",
    "    img = PythonMagick.Image()\n",
    "    img.density(\"600\")\n",
    "    img.read(filename+'['+ str(p) +']')\n",
    "    f=tempfile.NamedTemporaryFile(mode='w+b',suffix='.jpeg')\n",
    "    img.write(f.name)\n",
    "    print image_to_string(Image.open(f.name))\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import PythonMagick\n",
    "img = PythonMagick.Image()\n",
    "img.density(\"350\")\n",
    "img.read('data_0/pdf/0900045c80b013e1_ixs0586130022_f_pc_n_m.pdf') # read in at 300 dpi\n",
    "img.write(\"test.PNG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import html2text\n",
    "with open('data_0/html/0900045c80b013e1_ixs0586130022_f_pc_n_m_ocr.html','r') as f:\n",
    "    data=f.read()\n",
    "v=html2text.html2text(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data=None\n",
    "with open(data0+'/txt/0900045c82d7ac42_ocr.txt','r') as f:\n",
    "    data=f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['XS1061486434']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "tmp=data\n",
    "b=re.findall('[iI][sS][iI][nN].*\\n',tmp)\n",
    "tmp=' '.join(b)\n",
    "re.findall('[a-zA-Z][a-zA-Z][0-9][0-9][0-9][0-9][0-9][0-9][0-9][0-9][0-9][0-9]',tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['XS1061486434']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.get_from_field('fileId','0900045c82d7ac42')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import PyPDF2\n",
    "import tempfile\n",
    "import PythonMagick\n",
    "import Image\n",
    "from pytesseract import image_to_string\n",
    "import html2text\n",
    "import StringIO\n",
    "import re\n",
    "\n",
    "# HTML files seems to be the best !!!!!\n",
    "#\n",
    "def get_text(filename,isin=None):\n",
    "    '''\n",
    "    Recover the text from a file. \n",
    "    \n",
    "    args:\n",
    "        filename: name of the file to read. Format: txt, html, pdf, doc, jpeg or png\n",
    "        isin: is the isin is know and provided, check if the extracted isin match\n",
    "              if not, rais an error. Also help for evaluating the quality of ocr.\n",
    "              \n",
    "    \n",
    "    '''\n",
    "    assert os.path.isfile(filename)\n",
    "    if isin is None:\n",
    "        isin=re.findall('[a-zA-Z][a-zA-Z][0-9][0-9][0-9][0-9][0-9][0-9][0-9][0-9][0-9][0-9]',filename)\n",
    "        if len(isin)==1:\n",
    "            isin=isin[0]\n",
    "        else:\n",
    "            isin=None\n",
    "    ext = filename.strip().split('.')[-1].lower()\n",
    "    \n",
    "    result=None\n",
    "    if ext == 'txt':\n",
    "        with open(filename,'r') as f:\n",
    "            result=f.read().decode('utf8')\n",
    "        return result\n",
    "    elif ext == 'html':\n",
    "        with open(filename,'r') as f:\n",
    "            data=f.read().decode('utf8')\n",
    "        return html2text.html2text(data)\n",
    "    else:\n",
    "        npage=1\n",
    "        notok = True\n",
    "        result = StringIO.StringIO()\n",
    "        if ext == 'pdf':\n",
    "            # try to extract the text directly from the pdf\n",
    "            pdf_im = PyPDF2.PdfFileReader(file(filename, \"rb\"))\n",
    "            npage = pdf_im.getNumPages()            \n",
    "            for p in xrange(0,npage):\n",
    "                pageObj = pdf_im.getPage(p)\n",
    "                result.write(pageObj.extractText())\n",
    "            tmp=result.getvalue()\n",
    "            result.close() \n",
    "            result=tmp.replace('\\n',' ')\n",
    "            # test if if make sense and if we can extract the isin number, if not, this is probalby robish\n",
    "            b=re.findall('[iI][sS][iI][nN].{0,30}[a-zA-Z][a-zA-Z][0-9][0-9][0-9][0-9][0-9][0-9][0-9][0-9][0-9][0-9]',tmp)\n",
    "            tmp=' '.join(b)\n",
    "            isinfound=re.findall('[a-zA-Z][a-zA-Z][0-9][0-9][0-9][0-9][0-9][0-9][0-9][0-9][0-9][0-9]',tmp)\n",
    "            if isin is not None:\n",
    "                if len(isinfound) > 0 and isin in isinfound:\n",
    "                    notok = False\n",
    "            else:\n",
    "                if len(isinfound) > 0:\n",
    "                    notok = False  \n",
    "                    \n",
    "        if notok: # if it is robish, try to make an ocr...\n",
    "            result = StringIO.StringIO()  \n",
    "            for p in xrange(0,npage):\n",
    "                img = PythonMagick.Image()\n",
    "                img.density(\"600\")\n",
    "                img.read(filename+'['+ str(p) +']')\n",
    "                f=tempfile.NamedTemporaryFile(mode='w+b',suffix='.jpeg')\n",
    "                img.write(f.name)\n",
    "                result.write(image_to_string(Image.open(f.name)))\n",
    "                f.close()\n",
    "            tmp=result.getvalue()\n",
    "            result.close()\n",
    "            result=tmp\n",
    "        \n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print get_text('data_0/pdf/0900045c80b013e1_ixs0586130022_f_pc_n_m.pdf',isin=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print get_text('data_0/html/0900045c80b013e1_ixs0586130022_f_pc_n_m_ocr.html',isin=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print get_text('data_0/pdf/0900045c82ef7d9b_IXS1205574913_F_PC_N_M.pdf',isin=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "try to extract the isin of all file in html\n",
    "-------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create a dict with all the files to analize, when the isin can be extracted from the name,\n",
    "# it is directly used for indexing, if not found in the name, the files are added to the unknown list.\n",
    "data=label.from_folder(os.path.join(data0,'html'), header=['fileId', 'NOMINAL.CURR', 'MIN.TRAD.AMT',\n",
    "                                                       'MULT.TRAD.AMT', 'ZERO.COUPN.FLAG', 'SEC.SUB.ID',\n",
    "                                                       'FUNG.FL', 'OpCurrency', 'issuerName', 'issuerCity', \n",
    "                                                       'issuerCountry', 'guarantorName', 'guarantorCity', \n",
    "                                                       'guarantorCountry', 'City.Id', 'City.Name']\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ok=[]\n",
    "\n",
    "def add_isin(data,isin):\n",
    "    '''\n",
    "    add the isin to data it isin has only one element.\n",
    "    \n",
    "    return True if if has been added, false if several or no isin where provided\n",
    "    '''\n",
    "    if len(isin) == 1:\n",
    "        isin=isin.pop()\n",
    "        data[isin]=[[filename]]\n",
    "        data[isin].extend([None]*(len(data.header)-1))\n",
    "        return True\n",
    "    \n",
    "    return False\n",
    "        \n",
    "for filename in data.unknown:\n",
    "    if filename != '0900045c82a4ae5c_26022345_Aktienanleihe_19.11.2014_ocr.html': # this one is too long\n",
    "        tmp=get_text('data_0/html/'+filename)\n",
    "        tmp=tmp.replace('\\n',' ')\n",
    "        b=re.findall('[iI][sS][iI][nN].{0,30}[a-zA-Z][a-zA-Z][0-9][0-9][0-9][0-9][0-9][0-9][0-9][0-9][0-9][0-9]',tmp)\n",
    "        tmp=' '.join(b)\n",
    "        isin=set(re.findall('[a-zA-Z][a-zA-Z][0-9][0-9][0-9][0-9][0-9][0-9][0-9][0-9][0-9][0-9]',tmp))\n",
    "        \n",
    "        if add_isin(data,isin):\n",
    "            ok.append(filename)        \n",
    "        else:\n",
    "            # they are several isin which one is the right one ?\n",
    "            # if they are in the title, they usualy are the right one:\n",
    "            with open('data_0/html/'+filename) as p:\n",
    "                tmp=p.read()\n",
    "            tmp0=tmp.replace('\\n',' ')\n",
    "            b=re.findall('<h1.*?</h1>',tmp0)\n",
    "            tmp=' '.join(b)\n",
    "            isin1=set(re.findall('[a-zA-Z][a-zA-Z][0-9][0-9][0-9][0-9][0-9][0-9][0-9][0-9][0-9][0-9]',tmp))\n",
    "            if add_isin(data,isin1):\n",
    "                ok.append(filename)  \n",
    "            else:\n",
    "                # if it is in parentesis they should not be taken.\n",
    "                tmp=get_text('data_0/html/'+filename)\n",
    "                tmp=tmp.replace('\\n',' ')\n",
    "                b=re.findall('\\(.*?\\)',tmp)\n",
    "                tmp=' '.join(b)\n",
    "                isin1=set(re.findall('[a-zA-Z][a-zA-Z][0-9][0-9][0-9][0-9][0-9][0-9][0-9][0-9][0-9][0-9]',tmp))\n",
    "                delta=isin.difference(isin1)\n",
    "                if add_isin(data,delta):\n",
    "                    ok.append(filename) \n",
    "            \n",
    "for filename in ok:\n",
    "    data.unknown.remove(filename)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XS1267294996 None 0900045c83c404a2_IXS1267294996_F_PC_N_ocr.html\n",
      "XS1336577116 None 0900045c83b5181f_IXS1336577116_F_PC_N.html\n",
      "XS1190853736 None 0900045c8343d40b_SIGNED Amended & Restated Pricing supplement_Autocall_BRC_Shares(207781553_2) (..._ocr.html\n",
      "XS1267253299 None 0900045c83afbad4_IXS1267253299_F_PC_N_ocr.html\n",
      "XS1293123862 None 0900045c83b224e4_IXS1293123862_F_PC_N_ocr.html\n",
      "XS1313393214 None 0900045c83c0f80f_IXS1313393214_F_PC_N_ocr.html\n",
      "XS1190878139 None 0900045c82ea6f84_IXS1190878139_F_PC_N_ocr.html\n",
      "XS1190886314 None 0900045c82ee621c_IXS1190886314_F_PC_N_ocr.html\n",
      "XS1267292784 None 0900045c83c37d6d_IXS1267292784_F_PC_N_ocr.html\n",
      "xs1190853736 None 0900045c8343d409_amendment notice xs1190853736_ocr.html\n",
      "XS1190871472 None 0900045c83364a8b_IXS1190871472_F_PC_N_ocr.html\n",
      "XS1341173976 None 0900045c83bb0f07_IXS1341173976_F_PC_N_ocr.html\n",
      "XS1293114440 None 0900045c83ad8a5b_IXS1293114440 _F_PC_N_ocr.html\n",
      "XS1061486517 CH0210483332 0900045c82d7ac43_IXS1061486517_F_PC_N_ocr.html\n",
      "XS1190860194 None 0900045c83364a89_IXS1190860194_F_PC_N_ocr.html\n",
      "XS1190865151 None 0900045c8315b952_IXS1190865151_F_PC_N_ocr.html\n",
      "XS1267251087 None 0900045c83adf1c9_IXS1267251087_F_PC_N_ocr.html\n",
      "XS1293107071 None 0900045c83ab8766_IXS1293107071_F_PC_N_ocr.html\n",
      "XS1313396407 None 0900045c83c3eeef_IXS1313396407_F_PC_N.html\n",
      "XS1190858453 None 0900045c83314c84_IXS1190858453_F_PC_N_ocr.html\n",
      "XS1190859857 None 0900045c83364a8e_IXS1190859857_F_PC_N_ocr.html\n",
      "XS1267307301 None 0900045c83c7af99_IXS1267307301_F_PC_N_ocr.html\n",
      "XS1190880119 US0378331005 0900045c831219a8_IXS1190880119_F_PC_N_ocr.html\n",
      "XS1166358447 None 0900045c83095a2a_IXS1166358447_F_PC_N_ocr.html\n",
      "XS1267289996 None 0900045c83c13847_GSI 22 Jan 16_IXS1267289996_F_PC_N_ocr.html\n",
      "XS1267290226 None 0900045c83be6a78_IXS1267290226_F_PC_N_ocr.html\n",
      "XS1293098577 None 0900045c83aa098e_IXS1293098577_F_PC_N_ocr.html\n",
      "XS1267249693 None 0900045c83ac448e_IXS1267249693_F_PC_N_ocr.html\n",
      "XS1336577462 None 0900045c83bb0f0c_IXS1336577462_F_PC_N.html\n",
      "XS1338162677 None 0900045c83b2949e_IXS1338162677_F_PC_N_ocr.html\n",
      "XS1267291893 None 0900045c83c37d6e_IXS1267291893_F_PC_N_ocr.html\n",
      "XS1313800200 None 0900045c83b363af_IXS1313800200_F_PC_N.html\n",
      "XS1267279252 None 0900045c83be51ef_IXS1267279252_F_PC_N_ocr.html\n",
      "XS1313397983 None 0900045c83c3ef4e_IXS1313397983_F_PC_N_ocr.html\n",
      "XS1267234406 None 0900045c83a1e25b_IXS1267234406_F_PC_N_ocr.html\n",
      "XS1267303227 None 0900045c83c6c698_GSI 01 Feb_IXS1267303227_F_PC_N_ocr.html\n",
      "XS1267291117 None 0900045c83c20b13_IXS1267291117_F_PC.N_ocr.html\n",
      "XS1190867280 None 0900045c833a7155_IXS1190867280_F_PC_N_ocr.html\n",
      "XS1293104722 None 0900045c83ab929f_IXS1293104722_F_PC_N_ocr.html\n",
      "XS1190865235 None 0900045c8316e056_IXS1190865235_F_PC_N_ocr.html\n",
      "XS1267284252 None 0900045c83c03bf9_GSI 21 Jan_IXS1267284252_F_PC_N_ocr.html\n",
      "XS1190839743 None 0900045c8389117d_IXS1190839743_F_PC_N_ocr.html\n",
      "XS1190867447 None 0900045c830e2c02_IXS1190867447_F_PC_N_ocr.html\n",
      "XS1190849973 None 0900045c8357e604_IXS1190849973_F_PC_N_ocr.html\n",
      "XS1267290903 None 0900045c83c20c53_IXS1267290903_F_PC_N_ocr.html\n",
      "XS1267266275 None 0900045c83b50d42_IXS1267266275_F_PC_N_ocr.html\n",
      "XS1190879020 None 0900045c82ec2887_IXS1190879020_F_PC_N_ocr.html\n",
      "XS1190885340 None 0900045c82f60697_IXS1190885340_F_PC_N_ocr.html\n",
      "XS1190837457 None 0900045c8394b344_IXS1190837457_F_PC_N_ocr.html\n",
      "XS1336950958 None 0900045c83b724f2_IXS1336950958_F_PC_N.html\n",
      "XS1313390467 None 0900045c83bd88ea_IXS1313390467_F_PC_N_ocr.html\n",
      "XS1190859345 None 0900045c832d0c33_IXS1190859345_F_PC_N_ocr.html\n",
      "XS1190835329 None 0900045c839cadb5_IXS1190835329_F_PC_N_ocr.html\n",
      "XS1340850459 None 0900045c83bce1cc_IXS1340850459_F_PC_N_ocr.html\n",
      "XS1190881190 None 0900045c82e9552f_IXS1190881190_F_PC_N_ocr.html\n",
      "XS1190880978 None 0900045c82e122dc_IXS1190880978_F_PC_N_V02_ocr.html\n",
      "XS1190861325 None 0900045c83234d0d_IXS1190861325_F_PC_N_ocr.html\n",
      "XS1267314182 None 0900045c83c4c993_GSI 28 Jan_IXS1267314182_F_PC_N_ocr.html\n",
      "XS1313802750 None 0900045c83b129f4_IXS1313802750_F_PC_N.html\n",
      "XS1190865078 None 0900045c8315b954_IXS1190865078_F_PC_N_ocr.html\n",
      "XS1313803568 None 0900045c83b8a803_IXS1313803568_F_PC_N.html\n",
      "XS1190877677 US4655621062 0900045c83142dc9_IXS1190877677_F_PC_N_ocr.html\n",
      "XS1313808104 None 0900045c83bd8855_IXS1313808104_F_PC_N_ocr.html\n",
      "XS1190866639 None 0900045c833b5fd6_IXS1190866639_F_PC_N_ocr.html\n",
      "XS1190875978 None 0900045c8319ca9d_IXS1190875978_F_PC_N_ocr.html\n",
      "XS1061486434 CH0012255151 0900045c82d7ac42_IXS1061486434_F_PC_N_ocr.html\n",
      "XS1293112071 None 0900045c83b2ee3f_IXS1293112071_F_PC_N_ocr.html\n",
      "XS1190865581 None 0900045c831cddc8_IXS1190865581_F_PC_N_ocr.html\n",
      "XS1313800036 JP3386030005 0900045c83ac8dfe_IXS1313800036_F_PC_N.html\n",
      "XS1190863883 DE0007664039 0900045c833c8172_IXS1190863883_F_PC_N_ocr.html\n",
      "XS1190879376 None 0900045c82e62aae_IXS1190879376_F_PC_N_ocr.html\n",
      "XS1267301445 None 0900045c83c5ae0a_IXS1267301445_F_PC_N_ocr.html\n",
      "XS1190857216 None 0900045c83365ef3_IXS1190857216_F_PC_N_ocr.html\n",
      "XS1190850120 None 0900045c8357e602_IXS1190850120_F_PC_N_ocr.html\n",
      "XS1190870821 None 0900045c8303f310_IXS1190870821_F_PC_N_ocr.html\n",
      "XS1293110026 None 0900045c83b0853b_IXS1293110026_F_PC_N_ocr.html\n",
      "XS1190882917 None 0900045c8306254a_IXS1190882917_F_PC_N_ocr.html\n",
      "XS1293098650 None 0900045c83aa09a3_IXS1293098650_F_PC_N_ocr.html\n",
      "XS1267237920 None 0900045c83a62df4_IXS1267237920_F_PC_N_ocr.html\n",
      "XS1190861838 CH0012142631 0900045c834c6a30_IXS1190861838_F_PC_N_ocr.html\n",
      "XS1190862562 None 0900045c831ec330_IXS1190862562_F_PC_N_ocr.html\n",
      "XS1313800978 JP3183200009 0900045c83b42b06_IXS1313800978_F_PC_N.html\n",
      "xs0586130022 None 0900045c80b013e1_ixs0586130022_f_pc_n_m_ocr.html\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-53-6715b67f3967>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0mfilenames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0misin\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfilenames\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0mtest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mget_isin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data_0/html/'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0misin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m                 \u001b[0;32mprint\u001b[0m \u001b[0misin\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-53-6715b67f3967>\u001b[0m in \u001b[0;36mget_isin\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mtry\u001b[0m \u001b[0mto\u001b[0m \u001b[0mextract\u001b[0m \u001b[0mthe\u001b[0m \u001b[0misin\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     '''\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mtmp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mget_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mtmp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfindall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'[iI][sS][iI][nN].{0,30}[a-zA-Z][a-zA-Z][0-9][0-9][0-9][0-9][0-9][0-9][0-9][0-9][0-9][0-9]'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtmp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-a21bd2761305>\u001b[0m in \u001b[0;36mget_text\u001b[0;34m(filename, isin)\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mhtml2text\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhtml2text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0mnpage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/dist-packages/html2text/__init__.pyc\u001b[0m in \u001b[0;36mhtml2text\u001b[0;34m(html, baseurl, bodywidth)\u001b[0m\n\u001b[1;32m    928\u001b[0m     \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mHTML2Text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbaseurl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbaseurl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbodywidth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbodywidth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    929\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 930\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhtml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    931\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/dist-packages/html2text/__init__.pyc\u001b[0m in \u001b[0;36mhandle\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 271\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    272\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/dist-packages/html2text/__init__.pyc\u001b[0m in \u001b[0;36mfeed\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    266\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfeed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"</' + 'script>\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"</ignore>\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 268\u001b[0;31m         \u001b[0mHTMLParser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHTMLParser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/HTMLParser.pyc\u001b[0m in \u001b[0;36mfeed\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \"\"\"\n\u001b[1;32m    116\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrawdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrawdata\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgoahead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/HTMLParser.pyc\u001b[0m in \u001b[0;36mgoahead\u001b[0;34m(self, end)\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrawdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m             \u001b[0mmatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minteresting\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrawdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# < or &\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmatch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m                 \u001b[0mj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def get_isin(filename):\n",
    "    '''\n",
    "    try to extract the isin from the file\n",
    "    '''\n",
    "    tmp=get_text(filename)\n",
    "    tmp=tmp.replace('\\n',' ')\n",
    "    b=re.findall('[iI][sS][iI][nN].{0,30}[a-zA-Z][a-zA-Z][0-9][0-9][0-9][0-9][0-9][0-9][0-9][0-9][0-9][0-9]',tmp)\n",
    "    tmp=' '.join(b)\n",
    "    isin=set(re.findall('[a-zA-Z][a-zA-Z][0-9][0-9][0-9][0-9][0-9][0-9][0-9][0-9][0-9][0-9]',tmp))\n",
    "        \n",
    "    if len(isin) == 1:\n",
    "        return isin.pop()\n",
    "    else:\n",
    "        # they are several isin which one is the right one ?\n",
    "        # if they are in the title, they usualy are the right one:\n",
    "        with open(filename) as p:\n",
    "            tmp=p.read()\n",
    "        tmp0=tmp.replace('\\n',' ')\n",
    "        b=re.findall('<h1.*?</h1>',tmp0)\n",
    "        tmp=' '.join(b)\n",
    "        isinF1=set(re.findall('[a-zA-Z][a-zA-Z][0-9][0-9][0-9][0-9][0-9][0-9][0-9][0-9][0-9][0-9]',tmp))\n",
    "        if len(isinF1) == 1 :\n",
    "            return isinF1.pop()\n",
    "        else:\n",
    "            # if it is in parentesis they should not be taken.\n",
    "            tmp=get_text(filename)\n",
    "            tmp=tmp.replace('\\n',' ')\n",
    "            b=re.findall('\\(.*?\\)',tmp)\n",
    "            tmp=' '.join(b)\n",
    "            isinF1=set(re.findall('[a-zA-Z][a-zA-Z][0-9][0-9][0-9][0-9][0-9][0-9][0-9][0-9][0-9][0-9]',tmp))\n",
    "            delta=isinF.difference(isinF1)\n",
    "                \n",
    "            if len(isinF1) == 1 :\n",
    "                return isinF1.pop()  \n",
    "            else:\n",
    "                return None\n",
    "\n",
    "\n",
    "for isin in data:\n",
    "    filenames=data[isin][0]\n",
    "    for filename in filenames:\n",
    "        test=get_isin('data_0/html/'+filename)\n",
    "        if test is None or test.lower() != isin.lower():\n",
    "                print isin,test,filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ISIN  |  XS1267294996 ISIN:**  |  XS1267294996 ISIN: GB0005405286 ISIN: HK0000069689\n"
     ]
    }
   ],
   "source": [
    "def get_isin(filename):\n",
    "    '''\n",
    "    try to extract the isin from the file\n",
    "    '''\n",
    "    tmp=get_text(filename)\n",
    "    tmp=tmp.replace('\\n',' ')\n",
    "    b=re.findall('[iI][sS][iI][nN].{0,30}[a-zA-Z][a-zA-Z][0-9][0-9][0-9][0-9][0-9][0-9][0-9][0-9][0-9][0-9]',tmp)\n",
    "    tmp=' '.join(b)\n",
    "    print tmp\n",
    "    isin=set(re.findall('[a-zA-Z][a-zA-Z][0-9][0-9][0-9][0-9][0-9][0-9][0-9][0-9][0-9][0-9]',tmp))\n",
    "        \n",
    "    if len(isin) == 1:\n",
    "        return isin.pop()\n",
    "    else:\n",
    "        # they are several isin which one is the right one ?\n",
    "        # if they are in the title, they usualy are the right one:\n",
    "        with open(filename) as p:\n",
    "            tmp=p.read()\n",
    "        tmp0=tmp.replace('\\n',' ')\n",
    "        b=re.findall('<h1.*?</h1>',tmp0)\n",
    "        tmp=' '.join(b)\n",
    "        isinF1=set(re.findall('[a-zA-Z][a-zA-Z][0-9][0-9][0-9][0-9][0-9][0-9][0-9][0-9][0-9][0-9]',tmp))\n",
    "        if len(isinF1) == 1 :\n",
    "            return isinF1.pop()\n",
    "        else:\n",
    "            # if it is in parentesis they should not be taken.\n",
    "            tmp=get_text(filename)\n",
    "            tmp=tmp.replace('\\n',' ')\n",
    "            b=re.findall('\\(.*?\\)',tmp)\n",
    "            tmp=' '.join(b)\n",
    "            isinF1=set(re.findall('[a-zA-Z][a-zA-Z][0-9][0-9][0-9][0-9][0-9][0-9][0-9][0-9][0-9][0-9]',tmp))\n",
    "            delta=isinF.difference(isinF1)\n",
    "                \n",
    "            if len(isinF1) == 1 :\n",
    "                return isinF1.pop()  \n",
    "            else:\n",
    "                return None\n",
    "\n",
    "get_isin('data_0/html/'+'0900045c83c404a2_IXS1267294996_F_PC_N_ocr.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('/home/albert/Bureau/di hack/data_0/html/0900045c8321602e_DB6PNJ_FT legal.v1_ocr.html') as p:\n",
    "    tmp=p.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tmp=get_text('/home/albert/Bureau/di hack/data_0/html/0900045c8321602e_DB6PNJ_FT legal.v1_ocr.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall('<h1(!?</h1>).*?[iI][sS][iI][nN].*?[a-zA-Z][a-zA-Z][0-9][0-9][0-9][0-9][0-9][0-9][0-9][0-9][0-9][0-9].*?</h1>',tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<h1 style=\"padding-left: 156pt;text-indent: 0pt;text-align: left;\">DEUTSCHE BANK AG LONDON BRANCH</h1>', '<h1 style=\"padding-top: 10pt;padding-left: 27pt;text-indent: 0pt;text-align: center;\">Issue Price<span class=\"p\">: 100 per cent. of the Nominal Amount (Nominal Amount being EUR 1,000 per Security)</span></h1>', '<h1 style=\"padding-top: 5pt;padding-left: 41pt;text-indent: 0pt;text-align: center;\">WKN / ISIN<span class=\"p\">: DB6PNJ / XS0475698931</span></h1>', '<h1 style=\"padding-left: 5pt;text-indent: 0pt;text-align: justify;\">Terms and Conditions (Product Terms)</h1>', '<h1 style=\"padding-top: 6pt;padding-left: 5pt;text-indent: 0pt;text-align: justify;\">Further Information about the Offering of the Securities</h1>', '<h1 style=\"padding-left: 124pt;text-indent: 0pt;text-align: center;\">Terms and Conditions</h1>', '<h1 style=\"padding-left: 124pt;text-indent: 0pt;text-align: center;\">General Definitions applicable to the Securities</h1>', '<h1 style=\"padding-top: 4pt;padding-left: 113pt;text-indent: 0pt;text-align: left;\">Further Information about the Offering of the Securities</h1>', '<h1 style=\"padding-top: 4pt;padding-left: 16pt;text-indent: 0pt;text-align: justify;\">I<span class=\"h2\">NFORMATION RELATING TO THE </span>U<span class=\"h2\">NDERLYING</span>:</h1>', '<h1 style=\"padding-top: 3pt;padding-left: 5pt;text-indent: 0pt;text-align: left;\">Further Information Published by the Issuer</h1>', '<h1 style=\"padding-left: 5pt;text-indent: 0pt;text-align: left;\">R<span class=\"h2\">ESPONSIBILITY</span></h1>']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'XS0475698931'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('/home/albert/Bureau/di hack/data_0/html/0900045c8321602e_DB6PNJ_FT legal.v1_ocr.html') as p:\n",
    "    tmp=p.read()\n",
    "tmp=tmp.replace('\\n',' ')\n",
    "b=re.findall('<h1.*?</h1>',tmp)\n",
    "print b\n",
    "tmp=' '.join(b)\n",
    "set(re.findall('[a-zA-Z][a-zA-Z][0-9][0-9][0-9][0-9][0-9][0-9][0-9][0-9][0-9][0-9]',tmp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'ISIN: US1101221083', u'ISIN: US7170811035', u'ISIN:  |  XS1190853736']\n",
      "set([u'XS1190853736', u'US1101221083', u'US7170811035'])\n"
     ]
    }
   ],
   "source": [
    "tmp=get_text('data_0/html/0900045c8343d40b_SIGNED Amended & Restated Pricing supplement_Autocall_BRC_Shares(207781553_2) (..._ocr.html')\n",
    "#print tmp\n",
    "tmp=tmp.replace('\\n',' ')\n",
    "b=re.findall('[iI][sS][iI][nN].{0,30}[a-zA-Z][a-zA-Z][0-9][0-9][0-9][0-9][0-9][0-9][0-9][0-9][0-9][0-9]',tmp)\n",
    "print b\n",
    "tmp=' '.join(b)\n",
    "print set(re.findall('[a-zA-Z][a-zA-Z][0-9][0-9][0-9][0-9][0-9][0-9][0-9][0-9][0-9][0-9]',tmp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0900045c83aa81ef_206503_Termsheet_AP_GLOBAL__NIKKVELN13084HU.DKO_NKY__2_15.12._ocr.html',\n",
       " '0900045c839008e1_205034_Termsheet_AP_GLOBAL__Airbag_AMZN_DIS_NFLX_2_JPY_SMBCN__ocr.html',\n",
       " '0900045c839b32c6_205684_Termsheet_AP_GLOBAL__Airbag_AMZN_FB_UA_2_JPY_SMBCN_JAP_ocr.html',\n",
       " '0900045c83a9993d_206443_Termsheet_AP_GLOBAL__Airbag_FB_MET_6_SMBCN_JAPAN_FB__2_ocr.html',\n",
       " '0900045c839f9b64_205908_Termsheet_AP_GLOBAL__7974KELN10008MZ_7974__2_15.11.27__ocr.html',\n",
       " '0900045c83a0ada5_205949_Termsheet_AP_GLOBAL__Airbag_AAPL_AMZN_TSLA_41_JPY_SMBC_ocr.html',\n",
       " '0900045c83ad7126_206594_Termsheet_AP_GLOBAL__Airbag_AAPL_AMZN_FB_GOOGL_1_JPY_S_ocr.html',\n",
       " '0900045c839cef21_205793_Termsheet_AP_GLOBAL__Airbag_AMZN_FB_NFLX_1_JPY_SMBCN_J_ocr.html',\n",
       " '0900045c83ae485b_206627_Termsheet_AP_GLOBAL__6954KVELN10009MSPB.DKO_6954__2_15_ocr.html',\n",
       " '0900045c839ceeed_205791_Termsheet_AP_GLOBAL__Airbag_AAPL_AMZN_TWTR_1_JPY_SMBCN_ocr.html',\n",
       " '0900045c82a4ae5c_26022345_Aktienanleihe_19.11.2014_ocr.html']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.unknown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
