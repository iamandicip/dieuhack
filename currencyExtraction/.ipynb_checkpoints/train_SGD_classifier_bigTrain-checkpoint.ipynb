{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train_SGD_classifier_bigTrain\n",
    "score currency based on train set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named 'code.dataExtract'; 'code' is not a package",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-852b0fced7f4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m# data from Albert\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataExtract\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataExtract\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mde\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcode\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mText_reader\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named 'code.dataExtract'; 'code' is not a package"
     ]
    }
   ],
   "source": [
    "# SYSTEM\n",
    "from os import listdir\n",
    "import PyCommonFun \n",
    "\n",
    "#NLTK\n",
    "import nltk, re, pprint\n",
    "from nltk import word_tokenize\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.corpus import words\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.metrics import *\n",
    "from collections import Counter\n",
    "\n",
    "#GENERAL\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# data from Albert\n",
    "from code.dataExtract import data\n",
    "import code.dataExtract as de\n",
    "from code import Text_reader as tr\n",
    "# Read the data\n",
    "d = data(folder='../../train/') # training set with all the labels\n",
    "dataPath='../../train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def document_from_hmtl(doc_path):\n",
    "    with open(doc_path) as html_file:\n",
    "        full_text = html_file.read()\n",
    "        body = re.findall(r'<body[^>]*?>(.*?)</body>', full_text)\n",
    "        cleantext = re.sub('<\\/?span[^>]*>', ' ', body[0])\n",
    "        clean_text = re.sub('<.*?>', ' ', cleantext)\n",
    "        #clean_text = clean_text.lower()\n",
    "        clean_text = re.sub('0.01', '1', clean_text)\n",
    "        clean_text = re.sub(',', '', clean_text)\n",
    "        clean_text = re.sub(r'[^a-zA-Z0-9]', ' ', clean_text)\n",
    "        clean_text = re.sub('\\s+', ' ', clean_text)\n",
    "        return clean_text\n",
    "    \n",
    "def getContext(s,pattern,context=list(),width=100):\n",
    "    \n",
    "    \n",
    "    loc=s.find(pattern)\n",
    "    \n",
    "    if loc == -1:\n",
    "        return context\n",
    "    elif loc-width < 0:\n",
    "        context.append(s[:loc+width])\n",
    "        return getContext(s[loc+len(pattern):],pattern,context,width)\n",
    "    elif loc + width > len(s):\n",
    "        context.append(s[loc-width:])\n",
    "        return getContext(s[loc+len(pattern):],pattern,context,width)\n",
    "    else:\n",
    "        context.append(s[loc-width:loc+width])\n",
    "        return getContext(s[loc+len(pattern):],pattern,context,width)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load labels and context dict.\n",
    "the context dict is a dict. of dict. such as contextAllCurr = {'fileId': { ' curr' : Ngram } },\n",
    "where Ngramm are part of speech centered around a currency. The contextAllCurr has been \n",
    "saved in a separate notebook (save_curencyContext_train(test)Set.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# get context dict\n",
    "contextAllCurr=np.load(dataPath + '/train_contextAllCurr.npy').item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "extract only currencies found in the documents, store results in foundCurrType = {'fileId': [curr]}. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "contextOpCurr=dict()\n",
    "opCurrDict=dict()\n",
    "\n",
    "htmlFiles=tr.get_files(dataPath + '/html')\n",
    "\n",
    "for isin in d.docid.keys():\n",
    "    \n",
    "    contextOpCurr[isin]=contextAllCurr[isin][d.optCur[isin][0]]\n",
    "    opCurrDict[isin]=d.optCur[isin][0]\n",
    "    \n",
    "    if len(contextOpCurr[isin])==0:\n",
    "        contextOpCurr[isin]=document_from_hmtl(htmlFiles[d.docid[isin][0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ISIN</th>\n",
       "      <th>context</th>\n",
       "      <th>opCurr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XS1334556716</td>\n",
       "      <td>These Final Terms do not constitute Final Ter...</td>\n",
       "      <td>USD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XS1313800895</td>\n",
       "      <td>NO PROSPECTUS IS REQUIRED IN ACCORDANCE WITH ...</td>\n",
       "      <td>JPY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XS1378463068</td>\n",
       "      <td>Pricing Supplement The SFC takes no responsib...</td>\n",
       "      <td>HKD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>XS1267246327</td>\n",
       "      <td>Pricing Supplement dated December 10 2015 Exe...</td>\n",
       "      <td>USD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>US05579HAB87</td>\n",
       "      <td>[ Final Terms dated 17 December 2008 ING Bank ...</td>\n",
       "      <td>USD</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           ISIN                                            context opCurr\n",
       "0  XS1334556716   These Final Terms do not constitute Final Ter...    USD\n",
       "1  XS1313800895   NO PROSPECTUS IS REQUIRED IN ACCORDANCE WITH ...    JPY\n",
       "2  XS1378463068   Pricing Supplement The SFC takes no responsib...    HKD\n",
       "3  XS1267246327   Pricing Supplement dated December 10 2015 Exe...    USD\n",
       "4  US05579HAB87  [ Final Terms dated 17 December 2008 ING Bank ...    USD"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contextOpCurr_df=pd.DataFrame(contextOpCurr.items(),columns=['ISIN','context'])\n",
    "opCurr_df=pd.DataFrame(opCurrDict.items(),columns=['ISIN','opCurr'])\n",
    "contextOpCurr_df=pd.merge(contextOpCurr_df,opCurr_df,on='ISIN')\n",
    "contextOpCurr_df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5456\n",
      "5456\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "# export as np.array\n",
    "context=pickle.load(open('../context.pickle', 'rb'))\n",
    "opCurr=pickle.load(open('../opCurr.pickle', 'rb'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import cross_validation\n",
    "\n",
    "X_train, X_test, y_train, y_test = cross_validation.train_test_split(context, opCurr,\\\n",
    "                                                                     test_size=0.3, random_state=53)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'lower'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-43a76cdad527>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mtext_clf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext_clf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf__alpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1e-04\u001b[0m\u001b[0;34m,\u001b[0m                                \u001b[0mclf__n_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m                                \u001b[0mclf__penalty\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'l2'\u001b[0m\u001b[0;34m,\u001b[0m                                \u001b[0mtfidf__norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'l2'\u001b[0m\u001b[0;34m,\u001b[0m                                \u001b[0mtfidf__use_idf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m                                \u001b[0mvect__max_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.4\u001b[0m\u001b[0;34m,\u001b[0m                                \u001b[0mvect__ngram_range\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mtext_clf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext_clf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0my_train_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext_clf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ciprian/anaconda/lib/python3.5/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    162\u001b[0m             \u001b[0mthe\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m         \"\"\"\n\u001b[0;32m--> 164\u001b[0;31m         \u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pre_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ciprian/anaconda/lib/python3.5/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m_pre_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"fit_transform\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m                 \u001b[0mXt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params_steps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m                 \u001b[0mXt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params_steps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ciprian/anaconda/lib/python3.5/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m    815\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    816\u001b[0m         vocabulary, X = self._count_vocab(raw_documents,\n\u001b[0;32m--> 817\u001b[0;31m                                           self.fixed_vocabulary_)\n\u001b[0m\u001b[1;32m    818\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    819\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ciprian/anaconda/lib/python3.5/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m_count_vocab\u001b[0;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[1;32m    750\u001b[0m         \u001b[0mindptr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    751\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mraw_documents\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 752\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mfeature\u001b[0m \u001b[0;32min\u001b[0m \u001b[0manalyze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    753\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    754\u001b[0m                     \u001b[0mj_indices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocabulary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ciprian/anaconda/lib/python3.5/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(doc)\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m             return lambda doc: self._word_ngrams(\n\u001b[0;32m--> 238\u001b[0;31m                 tokenize(preprocess(self.decode(doc))), stop_words)\n\u001b[0m\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ciprian/anaconda/lib/python3.5/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlowercase\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstrip_accents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mstrip_accents\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'lower'"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "text_clf = Pipeline([('vect', CountVectorizer()), \\\n",
    "                     ('tfidf', TfidfTransformer()), \\\n",
    "                     ('clf', SGDClassifier(average=True))])\n",
    "\n",
    "text_clf = text_clf.set_params(clf__alpha = 1e-04, \\\n",
    "                               clf__n_iter = 100, \\\n",
    "                               clf__penalty = 'l2', \\\n",
    "                               tfidf__norm = 'l2', \\\n",
    "                               tfidf__use_idf = False, \\\n",
    "                               vect__max_df = 0.4, \\\n",
    "                               vect__ngram_range = (1, 2))\n",
    "\n",
    "text_clf = text_clf.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred = text_clf.predict(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Divide the foundCurrType in three dict:\n",
    " - single currency\n",
    " - multiple currency\n",
    " - void"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "voidCurr=dict()\n",
    "singleCurr=dict()\n",
    "multiCurr=dict()\n",
    "\n",
    "for key in foundCurrType:\n",
    "    if len(foundCurrType[key]) == 0:\n",
    "        voidCurr[key]=foundCurrType[key]\n",
    "    elif len(foundCurrType[key]) == 1:\n",
    "        singleCurr[key]=foundCurrType[key]\n",
    "    elif len(foundCurrType[key]) > 1:\n",
    "        multiCurr[key]=foundCurrType[key]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create bag of word for each currency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I want to get an idea of the association between the operationnal currency and the surrounding \n",
    "words. Ideally, the additionnal currency found in the docs should show differents association.\n",
    "\n",
    "To addess this point, I create two distinct bag of words (bow) associated to:\n",
    "1) operationnal currency (consider opCurr dict)\n",
    "2) additionnal  currency (consider multipleCurr dict)\n",
    "and compare the bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "text_bow_multiCurr=[]\n",
    "text_bow_OpCurr=[]\n",
    "\n",
    "for isin in multiCurr:\n",
    "    for curr in contextAllCurr[isin]:\n",
    "        # do not consider operationnal currency\n",
    "        if d.optCur[isin][0] == curr:\n",
    "            for content in contextAllCurr[isin][curr]:\n",
    "                text_bow_OpCurr.append(word_tokenize(content))\n",
    "        else:\n",
    "            for content in contextAllCurr[isin][curr]:\n",
    "                text_bow_multiCurr.append(word_tokenize(content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10145"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text_bow_multiCurr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tokenize the text but remove ponctuations\n",
    "tokenizer=RegexpTokenizer(r'\\w+')\n",
    "text_bow_OpCurr=tokenizer.tokenize(str(text_bow_OpCurr).lower())\n",
    "\n",
    "tokenizer=RegexpTokenizer(r'\\w+')\n",
    "text_bow_multiCurr=tokenizer.tokenize(str(text_bow_multiCurr).lower())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create a bag of word by counting number of occurence of each term\n",
    "\n",
    "bow_OpCurr=Counter(text_bow_OpCurr)\n",
    "len_text_OpCurr=len(text_bow_OpCurr)\n",
    "# normalize the bow by dividing by length of text\n",
    "for key, val in bow_OpCurr.iteritems():\n",
    "    bow_OpCurr[key]=np.float(bow_OpCurr[key])/len_text_OpCurr\n",
    "\n",
    "bow_multiCurr=Counter(text_bow_multiCurr)\n",
    "len_text_multiCurr=len(text_bow_multiCurr)\n",
    "# normalize the bow by dividing by length of text\n",
    "for key, val in bow_multiCurr.iteritems():\n",
    "    bow_multiCurr[key]=np.float(bow_multiCurr[key])/len_text_multiCurr\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# use set method to find common key between the bow\n",
    "key_OpCurr=set(bow_OpCurr)\n",
    "key_multiCurr_set=set(bow_multiCurr)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "178372"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len_text_OpCurr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the: 0.0508151503599\n",
      "date: 0.0259906263315\n",
      "currency: 0.0257383445832\n",
      "sprinter: 0.0247516426345\n",
      "as: 0.0187865808535\n",
      "usd: 0.0178895790819\n",
      "certificate: 0.01735698428\n",
      "trade: 0.0152434238558\n",
      "to: 0.0147837104478\n",
      "of: 0.0145370349606\n",
      "stop: 0.014099746597\n",
      "premium: 0.014099746597\n",
      "on: 0.014099746597\n",
      "loss: 0.014099746597\n",
      "trading: 0.0132812324804\n",
      "3: 0.0132419886529\n",
      "eur: 0.0123842307089\n",
      "time: 0.0122328616599\n",
      "specified: 0.0117563294688\n",
      "in: 0.0117563294688\n",
      "current: 0.0112797972776\n",
      "12: 0.0109378153522\n",
      "conditions: 0.0100800574081\n",
      "issued: 0.00931760590227\n",
      "rate: 0.00870652344538\n",
      "spread: 0.0084598479582\n",
      "maximum: 0.0084598479582\n",
      "applicable: 0.00828605386496\n",
      "price: 0.00826923508174\n",
      "issue: 0.00817392864351\n",
      "december: 0.00817392864351\n",
      "2008: 0.00817392864351\n",
      "settlement: 0.00792725315632\n",
      "quot: 0.00792725315632\n",
      "day: 0.00792725315632\n",
      "23: 0.00792725315632\n",
      "9: 0.00740587087659\n",
      "underlying: 0.00737223331016\n",
      "final: 0.00727692687193\n",
      "5: 0.00700782634046\n",
      "reset: 0.00678357589756\n",
      "level: 0.00678357589756\n",
      "financing: 0.00678357589756\n",
      "not: 0.00636310631713\n",
      "terms: 0.00613324961317\n",
      "provisions: 0.00613324961317\n",
      "page: 0.00613324961317\n",
      "17: 0.00588657412598\n",
      "13: 0.0056398986388\n",
      "11: 0.0056398986388\n",
      "disruption: 0.00521942905837\n",
      "1: 0.00520261027516\n",
      "event: 0.00497275357119\n",
      "00: 0.00491108469939\n",
      "certificates: 0.00457470903505\n",
      "reference: 0.00430560850358\n",
      "n: 0.00421030206535\n",
      "iii: 0.00421030206535\n",
      "has: 0.00421030206535\n",
      "by: 0.00421030206535\n",
      "150000: 0.00398044536138\n",
      "when: 0.00396362657816\n",
      "three: 0.00396362657816\n",
      "scheduled: 0.00396362657816\n",
      "preceding: 0.00396362657816\n",
      "if: 0.00396362657816\n",
      "exercise: 0.00396362657816\n",
      "european: 0.00396362657816\n",
      "entitlement: 0.00396362657816\n",
      "each: 0.00396362657816\n",
      "days: 0.00396362657816\n",
      "central: 0.00396362657816\n",
      "cash: 0.00396362657816\n",
      "business: 0.00396362657816\n",
      "and: 0.00396362657816\n",
      "amount: 0.00396362657816\n",
      "am: 0.00396362657816\n",
      "7: 0.00396362657816\n",
      "24: 0.00396362657816\n",
      "22: 0.00396362657816\n",
      "21: 0.00396362657816\n",
      "20: 0.00396362657816\n",
      "19: 0.00396362657816\n",
      "0: 0.00371695109098\n",
      "8: 0.00333011907699\n",
      "with: 0.00329648151055\n",
      "wmrspot39: 0.00306662480658\n",
      "v: 0.00306662480658\n",
      "these: 0.00306662480658\n",
      "sprinters: 0.00306662480658\n",
      "share: 0.00306662480658\n",
      "screen: 0.00306662480658\n",
      "reuters: 0.00306662480658\n",
      "relevant: 0.00306662480658\n",
      "referred: 0.00306662480658\n",
      "pursuant: 0.00306662480658\n",
      "prospectus: 0.00306662480658\n",
      "programme: 0.00306662480658\n",
      "p: 0.00306662480658\n",
      "minimis: 0.00306662480658\n",
      "market: 0.00306662480658\n",
      "linked: 0.00306662480658\n",
      "issuance: 0.00306662480658\n",
      "ing: 0.00306662480658\n",
      "ii: 0.00306662480658\n",
      "i: 0.00306662480658\n",
      "global: 0.00306662480658\n",
      "general: 0.00306662480658\n",
      "fx: 0.00306662480658\n",
      "events: 0.00306662480658\n",
      "eurusd: 0.00306662480658\n",
      "details: 0.00306662480658\n",
      "de: 0.00306662480658\n",
      "dated: 0.00306662480658\n",
      "crncy: 0.00306662480658\n",
      "completed: 0.00306662480658\n",
      "code: 0.00306662480658\n",
      "bloomberg: 0.00306662480658\n",
      "below: 0.00306662480658\n",
      "been: 0.00306662480658\n",
      "base: 0.00306662480658\n",
      "bank: 0.00306662480658\n",
      "a: 0.00306662480658\n",
      "80000000000: 0.00306662480658\n",
      "33: 0.00306662480658\n",
      "32: 0.00306662480658\n",
      "100: 0.00306662480658\n",
      "long: 0.00296571210728\n",
      "te: 0.0028199493194\n",
      "month: 0.0028199493194\n",
      "minimum: 0.0028199493194\n",
      "calendar: 0.0028199493194\n",
      "2: 0.0028199493194\n",
      "1st: 0.0028199493194\n",
      "16: 0.0028199493194\n",
      "15: 0.0028199493194\n",
      "14: 0.0028199493194\n",
      "10: 0.0028199493194\n",
      "4: 0.00260691139865\n",
      "short: 0.00238826721683\n",
      "ratings: 0.00228735451753\n",
      "euronext: 0.00228735451753\n",
      "be: 0.00228735451753\n",
      "commodity: 0.0022312919068\n",
      "wm: 0.00215280425179\n",
      "which: 0.00215280425179\n",
      "viii: 0.00215280425179\n",
      "vii: 0.00215280425179\n",
      "vi: 0.00215280425179\n",
      "valuation: 0.00215280425179\n",
      "termination: 0.00215280425179\n",
      "st: 0.00215280425179\n",
      "s: 0.00215280425179\n",
      "prepa: 0.00215280425179\n",
      "mi: 0.00215280425179\n",
      "mean: 0.00215280425179\n",
      "m: 0.00215280425179\n",
      "inconvertibili: 0.00215280425179\n",
      "greenwich: 0.00215280425179\n",
      "fixing: 0.00215280425179\n",
      "e: 0.00215280425179\n",
      "currently: 0.00215280425179\n",
      "company: 0.00215280425179\n",
      "certif: 0.00215280425179\n",
      "calculates: 0.00215280425179\n",
      "aximum: 0.00215280425179\n",
      "r: 0.00119413360841\n",
      "will: 0.00114367725876\n",
      "total: 0.00114367725876\n",
      "related: 0.00114367725876\n",
      "rated: 0.00114367725876\n",
      "provide: 0.00114367725876\n",
      "per: 0.00114367725876\n",
      "nyse: 0.00114367725876\n",
      "number: 0.00114367725876\n",
      "notification: 0.00114367725876\n",
      "netherlands: 0.00114367725876\n",
      "markets: 0.00114367725876\n",
      "issu: 0.00114367725876\n",
      "from: 0.00114367725876\n",
      "for: 0.00114367725876\n",
      "first: 0.00114367725876\n",
      "financial: 0.00114367725876\n",
      "expenses: 0.00114367725876\n",
      "estimate: 0.00114367725876\n",
      "effect: 0.00114367725876\n",
      "being: 0.00114367725876\n",
      "authority: 0.00114367725876\n",
      "amsterdam: 0.00114367725876\n",
      "aiw: 0.00114367725876\n",
      "admission: 0.00114367725876\n",
      "6: 0.00114367725876\n",
      "250: 0.00114367725876\n",
      "25: 0.00114367725876\n",
      "18: 0.00114367725876\n",
      "330: 0.00112685847555\n",
      "ncy: 0.000913820554796\n",
      "inconverti: 0.000913820554796\n",
      "ble: 0.000913820554796\n",
      "or: 0.000863364205144\n",
      "536: 0.000683963850829\n",
      "490: 0.000683963850829\n",
      "ximum: 0.000667145067612\n",
      "certi: 0.000667145067612\n",
      "770: 0.000667145067612\n",
      "740: 0.000667145067612\n",
      "38: 0.000667145067612\n",
      "291: 0.000650326284394\n",
      "370: 0.000476532191151\n",
      "390: 0.000341981925414\n",
      "350: 0.000341981925414\n",
      "69: 0.000280313053618\n",
      "ity: 0.000229856703967\n",
      "60000: 0.000229856703967\n",
      "06: 0.000229856703967\n",
      "86: 0.000224250442895\n",
      "45: 0.000128944004664\n"
     ]
    }
   ],
   "source": [
    "for key,value in sorted(bow_OpCurr.iteritems(), key=lambda (k,v):(v,k), reverse=True):\n",
    "    print '%s: %s' % (key,value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create a dictionnary with common keys, defined as the ratio of bow_OpCurr and bow_multiCurr, which is kind of weights\n",
    "bowRatio_intersect_curr=dict()\n",
    "for k in key_OpCurr.intersection(key_multiCurr_set):\n",
    "    bowRatio_intersect_curr[k] = bow_OpCurr[k]/bow_multiCurr[k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ximum: 1.74576959889\n",
      "certi: 1.74576959889\n",
      "770: 1.74576959889\n",
      "740: 1.74576959889\n",
      "38: 1.74576959889\n",
      "536: 1.7344265581\n",
      "490: 1.7344265581\n",
      "291: 1.60769154228\n",
      "te: 1.56578481656\n",
      "month: 1.56578481656\n",
      "minimum: 1.56578481656\n",
      "current: 1.56578481656\n",
      "calendar: 1.56578481656\n",
      "2: 1.56578481656\n",
      "1st: 1.56578481656\n",
      "16: 1.56578481656\n",
      "15: 1.56578481656\n",
      "14: 1.56578481656\n",
      "13: 1.56578481656\n",
      "11: 1.56578481656\n",
      "10: 1.56578481656\n",
      "stop: 1.56578481656\n",
      "spread: 1.56578481656\n",
      "premium: 1.56578481656\n",
      "on: 1.56578481656\n",
      "maximum: 1.56578481656\n",
      "loss: 1.56578481656\n",
      "event: 1.54442298634\n",
      "wm: 1.51730753995\n",
      "which: 1.51730753995\n",
      "viii: 1.51730753995\n",
      "vii: 1.51730753995\n",
      "vi: 1.51730753995\n",
      "valuation: 1.51730753995\n",
      "termination: 1.51730753995\n",
      "st: 1.51730753995\n",
      "s: 1.51730753995\n",
      "reference: 1.51730753995\n",
      "prepa: 1.51730753995\n",
      "mi: 1.51730753995\n",
      "mean: 1.51730753995\n",
      "m: 1.51730753995\n",
      "inconvertibili: 1.51730753995\n",
      "greenwich: 1.51730753995\n",
      "fixing: 1.51730753995\n",
      "e: 1.51730753995\n",
      "currently: 1.51730753995\n",
      "company: 1.51730753995\n",
      "certif: 1.51730753995\n",
      "calculates: 1.51730753995\n",
      "aximum: 1.51730753995\n",
      "390: 1.4888440366\n",
      "350: 1.4888440366\n",
      "9: 1.4298853223\n",
      "330: 1.41780699355\n",
      "1: 1.38348374881\n",
      "0: 1.36460369926\n",
      "trade: 1.33554111123\n",
      "commodity: 1.32252166111\n",
      "3: 1.28973456459\n",
      "12: 1.27539749082\n",
      "specified: 1.27363428925\n",
      "in: 1.27363428925\n",
      "rate: 1.26385631014\n",
      "370: 1.22099957065\n",
      "underlying: 1.20371711446\n",
      "date: 1.20137109709\n",
      "price: 1.17337273591\n",
      "the: 1.16224447813\n",
      "17: 1.15698109771\n",
      "8: 1.15615060014\n",
      "usd: 1.1319421206\n",
      "reset: 1.12857872746\n",
      "level: 1.12857872746\n",
      "financing: 1.12857872746\n",
      "as: 1.12311746229\n",
      "disruption: 1.10916587602\n",
      "time: 1.08667483298\n",
      "5: 1.07937639308\n",
      "currency: 1.07442355291\n",
      "applicable: 1.03671346467\n",
      "conditions: 1.02457119053\n",
      "00: 0.956842678101\n",
      "when: 0.941536431498\n",
      "three: 0.941536431498\n",
      "settlement: 0.941536431498\n",
      "scheduled: 0.941536431498\n",
      "quot: 0.941536431498\n",
      "preceding: 0.941536431498\n",
      "if: 0.941536431498\n",
      "exercise: 0.941536431498\n",
      "european: 0.941536431498\n",
      "entitlement: 0.941536431498\n",
      "each: 0.941536431498\n",
      "days: 0.941536431498\n",
      "day: 0.941536431498\n",
      "central: 0.941536431498\n",
      "cash: 0.941536431498\n",
      "business: 0.941536431498\n",
      "and: 0.941536431498\n",
      "amount: 0.941536431498\n",
      "am: 0.941536431498\n",
      "7: 0.941536431498\n",
      "24: 0.941536431498\n",
      "23: 0.941536431498\n",
      "22: 0.941536431498\n",
      "21: 0.941536431498\n",
      "20: 0.941536431498\n",
      "19: 0.941536431498\n",
      "wmrspot39: 0.932985986455\n",
      "v: 0.932985986455\n",
      "these: 0.932985986455\n",
      "terms: 0.932985986455\n",
      "sprinters: 0.932985986455\n",
      "share: 0.932985986455\n",
      "screen: 0.932985986455\n",
      "reuters: 0.932985986455\n",
      "relevant: 0.932985986455\n",
      "referred: 0.932985986455\n",
      "pursuant: 0.932985986455\n",
      "provisions: 0.932985986455\n",
      "prospectus: 0.932985986455\n",
      "programme: 0.932985986455\n",
      "page: 0.932985986455\n",
      "p: 0.932985986455\n",
      "minimis: 0.932985986455\n",
      "market: 0.932985986455\n",
      "linked: 0.932985986455\n",
      "issuance: 0.932985986455\n",
      "ing: 0.932985986455\n",
      "ii: 0.932985986455\n",
      "i: 0.932985986455\n",
      "global: 0.932985986455\n",
      "general: 0.932985986455\n",
      "fx: 0.932985986455\n",
      "events: 0.932985986455\n",
      "eurusd: 0.932985986455\n",
      "details: 0.932985986455\n",
      "de: 0.932985986455\n",
      "dated: 0.932985986455\n",
      "crncy: 0.932985986455\n",
      "completed: 0.932985986455\n",
      "code: 0.932985986455\n",
      "bloomberg: 0.932985986455\n",
      "below: 0.932985986455\n",
      "been: 0.932985986455\n",
      "base: 0.932985986455\n",
      "bank: 0.932985986455\n",
      "a: 0.932985986455\n",
      "80000000000: 0.932985986455\n",
      "33: 0.932985986455\n",
      "32: 0.932985986455\n",
      "100: 0.932985986455\n",
      "certificate: 0.922220309375\n",
      "not: 0.894387315754\n",
      "with: 0.861241245375\n",
      "of: 0.854120685182\n",
      "issue: 0.825199444262\n",
      "december: 0.825199444262\n",
      "2008: 0.825199444262\n",
      "sprinter: 0.818049687646\n",
      "final: 0.810118416464\n",
      "trading: 0.803758819496\n",
      "to: 0.798869232167\n",
      "eur: 0.7938074051\n",
      "150000: 0.77215931282\n",
      "issued: 0.75665788941\n",
      "4: 0.749112435871\n",
      "n: 0.73921304149\n",
      "iii: 0.73921304149\n",
      "has: 0.73921304149\n",
      "by: 0.73921304149\n",
      "long: 0.702790912344\n",
      "short: 0.614818215797\n",
      "69: 0.520381615018\n",
      "r: 0.495745827168\n",
      "ncy: 0.489181368024\n",
      "inconverti: 0.489181368024\n",
      "ble: 0.489181368024\n",
      "will: 0.474798820386\n",
      "total: 0.474798820386\n",
      "related: 0.474798820386\n",
      "ratings: 0.474798820386\n",
      "rated: 0.474798820386\n",
      "provide: 0.474798820386\n",
      "per: 0.474798820386\n",
      "nyse: 0.474798820386\n",
      "number: 0.474798820386\n",
      "notification: 0.474798820386\n",
      "netherlands: 0.474798820386\n",
      "markets: 0.474798820386\n",
      "issu: 0.474798820386\n",
      "from: 0.474798820386\n",
      "for: 0.474798820386\n",
      "first: 0.474798820386\n",
      "financial: 0.474798820386\n",
      "expenses: 0.474798820386\n",
      "euronext: 0.474798820386\n",
      "estimate: 0.474798820386\n",
      "effect: 0.474798820386\n",
      "certificates: 0.474798820386\n",
      "being: 0.474798820386\n",
      "be: 0.474798820386\n",
      "authority: 0.474798820386\n",
      "amsterdam: 0.474798820386\n",
      "aiw: 0.474798820386\n",
      "admission: 0.474798820386\n",
      "6: 0.474798820386\n",
      "250: 0.474798820386\n",
      "25: 0.474798820386\n",
      "18: 0.474798820386\n",
      "86: 0.465489039594\n",
      "or: 0.462171353838\n",
      "ity: 0.425108740389\n",
      "60000: 0.425108740389\n",
      "06: 0.425108740389\n",
      "45: 0.420096151461\n"
     ]
    }
   ],
   "source": [
    "# check if it looks ok\n",
    "for key,value in sorted(bowRatio_intersect_curr.iteritems(), key=lambda (k,v):(v,k), reverse=True):\n",
    "    print '%s: %s' % (key,value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## save the weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.save('weight_forCurrencyScoring_bigTrain.npy', bowRatio_intersect_curr) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
