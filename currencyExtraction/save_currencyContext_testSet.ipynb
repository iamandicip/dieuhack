{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save_currencyContext_testSet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save a large dictionnary with:\n",
    "- first key: file ID\n",
    "- second key: currency\n",
    "\n",
    "the dict store list of words appearing before and after a currency (acronym). \n",
    "This dict will be further used to defined a rule to select only nominal and \n",
    "operationnal frequency \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# SYSTEM\n",
    "from os import listdir\n",
    "from PyCommonFun import *\n",
    "\n",
    "#NLTK\n",
    "import nltk, re, pprint\n",
    "from nltk import word_tokenize\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.corpus import words\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.metrics import *\n",
    "\n",
    "#GENERAL\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get the solution\n",
    "labels=pd.read_csv('../../data_0/greg_test_set/lab_greg_test_set.csv')\n",
    "curr_df=pd.read_csv('currencies.csv')\n",
    "currCode=curr_df['Alphabetic Code'].values\n",
    "#currCode=['USD','GBP','HSK','JPY','EUR','CNY']\n",
    "#currCode=np.unique(labels.OpCurrency.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/382\n",
      "2/382\n",
      "3/382\n",
      "4/382\n",
      "5/382\n",
      "6/382\n",
      "7/382\n",
      "8/382\n",
      "9/382\n",
      "10/382\n",
      "11/382\n",
      "12/382\n",
      "13/382\n",
      "14/382\n",
      "15/382\n",
      "16/382\n",
      "17/382\n",
      "18/382\n",
      "19/382\n",
      "20/382\n",
      "21/382\n",
      "22/382\n",
      "23/382\n",
      "24/382\n",
      "25/382\n",
      "26/382\n",
      "27/382\n",
      "28/382\n",
      "29/382\n",
      "30/382\n",
      "31/382\n",
      "32/382\n",
      "33/382\n",
      "34/382\n",
      "35/382\n",
      "36/382\n",
      "37/382\n",
      "38/382\n",
      "39/382\n",
      "40/382\n",
      "41/382\n",
      "42/382\n",
      "43/382\n",
      "44/382\n",
      "45/382\n",
      "46/382\n",
      "47/382\n",
      "48/382\n",
      "49/382\n",
      "50/382\n",
      "51/382\n",
      "52/382\n",
      "53/382\n",
      "54/382\n",
      "55/382\n",
      "56/382\n",
      "57/382\n",
      "58/382\n",
      "59/382\n",
      "60/382\n",
      "61/382\n",
      "62/382\n",
      "63/382\n",
      "64/382\n",
      "65/382\n",
      "66/382\n",
      "67/382\n",
      "68/382\n",
      "69/382\n",
      "70/382\n",
      "71/382\n",
      "72/382\n",
      "73/382\n",
      "74/382\n",
      "75/382\n",
      "76/382\n",
      "77/382\n",
      "78/382\n",
      "79/382\n",
      "80/382\n",
      "81/382\n",
      "82/382\n",
      "83/382\n",
      "84/382\n",
      "85/382\n",
      "86/382\n",
      "87/382\n",
      "88/382\n",
      "89/382\n",
      "90/382\n",
      "91/382\n",
      "92/382\n",
      "93/382\n",
      "94/382\n",
      "95/382"
     ]
    }
   ],
   "source": [
    "%timeit\n",
    "\n",
    "contextOpCurr=dict()\n",
    "contextAllCurr=dict()\n",
    "\n",
    "gc=0\n",
    "\n",
    "for f in labels.fileId:\n",
    "    gc+=1\n",
    "    print str(gc)+'/'+str(len(labels.fileId))\n",
    "    fileOpen=open('../../data_0/greg_test_set/txt/' + f + '_ocr.txt')\n",
    "    text=fileOpen.read()\n",
    "    text=unicode(text, 'ascii', 'ignore')\n",
    "    \n",
    "    word=word_tokenize(text)\n",
    "    contextOpCurr[f]=[]\n",
    "    contextAllCurr[f]=dict()\n",
    "    \n",
    "    lenGram=10\n",
    "\n",
    "    for curr in currCode:\n",
    "        gw=0\n",
    "        contextAllCurr[f][curr]=[]\n",
    "        for w in word:\n",
    "            if curr == w:\n",
    "                contextAllCurr[f][curr].append(word[gw-lenGram:gw+lenGram])\n",
    "            gw+=1\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.save('../../data_0/greg_test_set/contextAllCurr.npy', contextAllCurr) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
