{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description of the method and corresponding notebooks\n",
    "\n",
    "### I) Split data into train and test set :\n",
    "$\\textbf{divide_data0_train_test_set.ipynb}$\n",
    "\n",
    "###  II) Match currency occurence in each document and extract the surroundings words\n",
    "- word_tokenize documents, then compare word with currency acronym (defined in \"currencies.csv\"). If it is a match I extract the context, say what $\\pm$ 10 words between the occurence of the currency\n",
    "- the \"sentences\" are stored in a dict of dict of list, where key 1 and key 2 correponds to fileId and currency respectively, elements of the list are the sentences containing the currency. \n",
    "- Do it for train set: $\\textbf{save_currencyContext_trainSet.ipynb}$\n",
    "- Do it for test set: $\\textbf{save_currencyContext_testSet.ipynb}$\n",
    "\n",
    "We can face tree cases:\n",
    "- a single currency is found in the document ( $\\sim$75% of the cases) . Easy peasy, we get directly the operationnal currency\n",
    "- no currency, corresponds to doc (I worked with .txt files) with OCR problems\n",
    "- several currencies are found. The question is obviously how to extract the operationnal currency and reject the others? That's where I use the context defined in sec II. Explanations are detailed below.\n",
    "\n",
    "### III) build a weight from the train set\n",
    "\n",
    "For the train set, I define two bags of words (bow) from the context:\n",
    "- bow_OpCurr: a bow associated to the operational currency \n",
    "- bow_multiCurr: a bow associated to dummy currencies\n",
    "\n",
    "The bow are dictionnaries with key, value corresponing to words and associated frequencies. \n",
    "I extract the keys common to the 2 bow dict and built and additionnal dict such as\n",
    "weight[key]=bow_OpCurr[key]/bow_multiCurr[key].\n",
    "\n",
    "Obviously the weights are large for words that are often found \n",
    "around the operationnal currency and rarely found with the dummy currencies. \n",
    "\n",
    "\n",
    "corresponding notebook: $\\textbf{create_scoringDict_fromTrainSet.ipynb}$\n",
    "\n",
    "### IV) Score the multiple currencies \n",
    "\n",
    "In extract_currency_testSet.ipynb, weight is used to discriminate between multiple currencies.\n",
    "The currency with the highest score is kept. \n",
    "\n",
    "### V) check against ground truth\n",
    "\n",
    "$\\textbf{check_extractedOpCurr.ipynb}$\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
